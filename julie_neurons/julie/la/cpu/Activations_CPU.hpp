/******************************************************************************
 *             Copyright 2020 DeepFrame AI
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 ******************************************************************************/

#pragma once
#include "Matrix_CPU.hpp"

namespace julie
{
namespace la
{
namespace cpu
{

/*********************************************************************************
 * This is the abstract base class of all CPU mode activation functions that do not
 * hold trainable parameters. For example: Sigmoid, ReLU, etc. Activation functions
 * like PReLU that holds alpha as a trainable parameter will not derive from
 * this base class.
 *********************************************************************************/
template <typename DT>
class Activation_CPU
{
public:

    // Default constructor
    Activation_CPU() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in) = 0;

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in) = 0;
};

template <typename DT>
class Linear : public Activation_CPU<DT>
{
public:
    Linear() {};

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class Sigmoid : public Activation_CPU<DT>
{
public:
    Sigmoid() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class TanH : public Activation_CPU<DT>
{
public:
    TanH() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class ReLU : public Activation_CPU<DT>
{
public:
    ReLU() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class LeakyReLU : public Activation_CPU<DT>
{
public:
    LeakyReLU() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class Abs : public Activation_CPU<DT>
{
public:
    Abs() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class ArcTan : public Activation_CPU<DT>
{
public:
    ArcTan() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class Sin : public Activation_CPU<DT>
{
public:
    Sin() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class SoftSign : public Activation_CPU<DT>
{
public:
    SoftSign() {}

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);
};

template <typename DT>
class SoftMax : public Activation_CPU<DT>
{
public:

    // SoftMax needs a dimension index (axis) to run with.
    // Size of this dimension indicates numbers classes softmax needs to classify.
    SoftMax(lint axis) : m_axis {axis} {};

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, Matrix_CPU<DT> & diff, const Matrix_CPU<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    virtual void operator () (Matrix_CPU<DT> & output, const Matrix_CPU<DT> & in);

private:

    // We suppose there is a matrix of shape (a, b, c, d) that softmax function will deal with.
    // And the axis index for softmax is 1, then softmax should run on the b dimension.
    // So, there will be a * c * d elementary_softmax jobs to run.
    // Arguments:
    //     output:    Softmax output
    //     input:     input matrix
    //     size:      Size of the dimension (axis) softmax will run with
    //     r_sh_size: Size of all dimensions staying at right side of the softmax dimension.
    //                r_sh_size will be c * d in the above example.
    void elementary_softmax(DT *output, const DT *input, lint size, lint r_sh_size);

    // We suppose there is a matrix of shape (a, b, c, d) that softmax function will deal with.
    // And the axis index for softmax is 1, then softmax should run on the b dimension.
    // So, there will be a * c * d elementary_softmax jobs to run.
    // Arguments:
    //     output:    Softmax output
    //     diff:      The derivative d(output) / d(input)
    //     input:     input matrix
    //     size:      Size of the dimension (axis) softmax will run with
    //     r_sh_size: Size of all dimensions staying at right side of the softmax dimension.
    //                r_sh_size will be c * d in the above example.
    void elementary_softmax(DT *output, DT *diff, const DT *input, lint size, lint r_sh_size);

private:
    lint m_axis;
};

} // namespace cpu
} // namespace la
} // namespace julie
