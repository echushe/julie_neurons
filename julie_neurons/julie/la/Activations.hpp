/******************************************************************************
 *             Copyright 2020 DeepFrame AI
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 ******************************************************************************/

#pragma once
#include "iMatrix.hpp"
#include "Activations_CPU.hpp"
#ifdef WITH_CUDA
#include "Activations_CUDA.hpp"
#endif

namespace julie
{
namespace la
{

/*********************************************************************************
 * This is the base class of all raw activation functions that do not hold
 * trainable parameters. For example: Sigmoid, ReLU, etc. Activation functions
 * like PReLU that holds alpha as a trainable parameter will not derive from
 * this base class.
 *********************************************************************************/
template <typename DT>
class Activation
{

public:

    // Default constructor
    Activation();

    // Forward operation of the activation giving the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     diff:   The derivative d(output) / d(input) generated by this activation function
    //     in:     Input of this activation function
    // Returns:    void
    void operator () (iMatrix<DT> & output, iMatrix<DT> & diff, const iMatrix<DT> & in);

    // Forward operation of the activation without providing the activation's derivative
    // Arguments:
    //     output: Output of this activation function
    //     in:     Input of this activation function
    // Returns:    void
    void operator () (iMatrix<DT> & output, const iMatrix<DT> & in);

protected:

    // Reference to the naked CPU type activation function.
    // This reference will be instantiated by derived classes (ReLU, Sigmoid, SoftMax, etc).
    std::shared_ptr<cpu::Activation_CPU<DT>> m_act_cpu;

#ifdef WITH_CUDA
    // Reference to the naked CUDA type activation function.
    // This reference will be instantiated by derived classes (ReLU, Sigmoid, SoftMax, etc).
    std::shared_ptr<cuda::Activation_CUDA<DT>> m_act_cuda;
#endif
};

template <typename DT>
class Linear : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    Linear();
};

template <typename DT>
class Sigmoid : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    Sigmoid();
};

template <typename DT>
class TanH : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    TanH();
};

template <typename DT>
class ReLU : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    ReLU();
};

template <typename DT>
class Abs : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    Abs();
};

template <typename DT>
class LeakyReLU : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    LeakyReLU();
};

template <typename DT>
class ArcTan : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    ArcTan();
};

template <typename DT>
class Sin : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    Sin();
};

template <typename DT>
class SoftSign : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    SoftSign();
};

template <typename DT>
class SoftMax : public Activation<DT>
{
public:

    // Constructor to instantiate "naked" activation implementations
    // that run on CPU, CUDA, etc.
    // SoftMax needs a dimension index (axis) to run with.
    // Size of this dimension indicates numbers classes softmax needs to classify.
    SoftMax(lint axis);
};

}  // namespace la
}  // namespace julie

